{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import pickle\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Loading done'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''For Training dataset'''\n",
    "# path = './data/train_dataset/'\n",
    "# name = os.listdir(path)\n",
    "# folder_name = ['1','2','3','4','5','6','7','8','9','10']\n",
    "\n",
    "'''Creating a folder for all of the reviews based on it's rating from 1 to 10 for training dataset.'''\n",
    "# for x in range(0,10):\n",
    "#     if not os.path.exists(path +folder_name[x]):\n",
    "#         os.makedirs(path+folder_name[x])\n",
    "\n",
    "'''Sorting each text file into a directory according to it's review rating for training dataset.'''\n",
    "# for file in name:\n",
    "#     if \"*_1.txt\" in file and not os.path.exists(path +'1/' +file):\n",
    "#         shutil.move(path+file, path +'1/' +file)\n",
    "#     if \"*_2.txt\" in file and not os.path.exists(path +'2/' +file):\n",
    "#         shutil.move(path+file, path +'2/' +file)\n",
    "#     if \"*_3.txt\" in file and not os.path.exists(path +'3/' +file):\n",
    "#         shutil.move(path+file, path +'3/' +file)\n",
    "#     if \"*_4.txt\" in file and not os.path.exists(path +'4/' +file):\n",
    "#         shutil.move(path+file, path +'4/' +file)\n",
    "#     if \"*_5.txt\" in file and not os.path.exists(path +'5/' +file):\n",
    "#         shutil.move(path+file, path +'5/' +file)\n",
    "#     if \"*_6.txt\" in file and not os.path.exists(path +'6/' +file):\n",
    "#         shutil.move(path+file, path +'6/' +file)\n",
    "#     if \"*_7.txt\" in file and not os.path.exists(path +'7/' +file):\n",
    "#         shutil.move(path+file, path +'7/' +file)\n",
    "#     if \"*_8.txt\" in file and not os.path.exists(path +'8/' +file):\n",
    "#         shutil.move(path+file, path +'8/' +file)\n",
    "#     if \"*_9.txt\" in file and not os.path.exists(path +'9/' +file):\n",
    "#         shutil.move(path+file, path +'9/' +file)\n",
    "#     if \"*_10.txt\" in file and not os.path.exists(path +'10/' +file):\n",
    "#         shutil.move(path+file, path +'10/' +file)\n",
    "\n",
    "'''For Testing dataset'''\n",
    "# path = './data/test_dataset/'\n",
    "# name = os.listdir(path)\n",
    "# folder_name = ['1','2','3','4','5','6','7','8','9','10']\n",
    "\n",
    "'''Creating a folder for all of the reviews based on it's rating from 1 to 10 for testing dataset.'''\n",
    "# for x in range(0,10):\n",
    "#     if not os.path.exists(path +folder_name[x]):\n",
    "#         os.makedirs(path+folder_name[x])\n",
    "\n",
    "'''Sorting each text file into a directory according to it's review rating for training dataset.'''\n",
    "# for file in name:\n",
    "#     if \"*_1.txt\" in file and not os.path.exists(path +'1/' +file):\n",
    "#         shutil.move(path+file, path +'1/' +file)\n",
    "#     if \"*_2.txt\" in file and not os.path.exists(path +'2/' +file):\n",
    "#         shutil.move(path+file, path +'2/' +file)\n",
    "#     if \"*_3.txt\" in file and not os.path.exists(path +'3/' +file):\n",
    "#         shutil.move(path+file, path +'3/' +file)\n",
    "#     if \"*_4.txt\" in file and not os.path.exists(path +'4/' +file):\n",
    "#         shutil.move(path+file, path +'4/' +file)\n",
    "#     if \"*_5.txt\" in file and not os.path.exists(path +'5/' +file):\n",
    "#         shutil.move(path+file, path +'5/' +file)\n",
    "#     if \"*_6.txt\" in file and not os.path.exists(path +'6/' +file):\n",
    "#         shutil.move(path+file, path +'6/' +file)\n",
    "#     if \"*_7.txt\" in file and not os.path.exists(path +'7/' +file):\n",
    "#         shutil.move(path+file, path +'7/' +file)\n",
    "#     if \"*_8.txt\" in file and not os.path.exists(path +'8/' +file):\n",
    "#         shutil.move(path+file, path +'8/' +file)\n",
    "#     if \"*_9.txt\" in file and not os.path.exists(path +'9/' +file):\n",
    "#         shutil.move(path+file, path +'9/' +file)\n",
    "#     if \"*_10.txt\" in file and not os.path.exists(path +'10/' +file):\n",
    "#         shutil.move(path+file, path +'10/' +file)\n",
    "        \n",
    "# df1 = pd.read_csv('train_dataset/train_dataset_1.csv')\n",
    "# df2 = pd.read_csv('train_dataset/train_dataset_2.csv')\n",
    "# df3 = pd.read_csv('train_dataset/train_dataset_3.csv')\n",
    "# df4 = pd.read_csv('train_dataset/train_dataset_4.csv')\n",
    "# df5 = pd.read_csv('train_dataset/train_dataset_5.csv')\n",
    "# df6 = pd.read_csv('train_dataset/train_dataset_6.csv')\n",
    "# df7 = pd.read_csv('train_dataset/train_dataset_7.csv')\n",
    "# df8 = pd.read_csv('train_dataset/train_dataset_8.csv')\n",
    "# df9 = pd.read_csv('train_dataset/train_dataset_9.csv')\n",
    "# df10 = pd.read_csv('train_dataset/train_dataset_10.csv')\n",
    "\n",
    "# df11 = pd.read_csv('test_dataset/test_dataset_1.csv')\n",
    "# df12 = pd.read_csv('test_dataset/test_dataset_2.csv')\n",
    "# df13 = pd.read_csv('test_dataset/test_dataset_3.csv')\n",
    "# df14 = pd.read_csv('test_dataset/test_dataset_4.csv')\n",
    "# df15 = pd.read_csv('test_dataset/test_dataset_5.csv')\n",
    "# df16 = pd.read_csv('test_dataset/test_dataset_6.csv')\n",
    "# df17 = pd.read_csv('test_dataset/test_dataset_7.csv')\n",
    "# df18 = pd.read_csv('test_dataset/test_dataset_8.csv')\n",
    "# df19 = pd.read_csv('test_dataset/test_dataset_9.csv')\n",
    "# df20 = pd.read_csv('test_dataset/test_dataset_10.csv')\n",
    "\n",
    "'''Create a column for the current class for all datasets'''\n",
    "# df1['Class'] = '1'\n",
    "# df2['Class'] = '2'\n",
    "# df3['Class'] = '3'\n",
    "# df4['Class'] = '4'\n",
    "# df5['Class'] = '5'\n",
    "# df6['Class'] = '6'\n",
    "# df7['Class'] = '7'\n",
    "# df8['Class'] = '8'\n",
    "# df9['Class'] = '9'\n",
    "# df10['Class'] = '10'\n",
    "\n",
    "# df11['Class'] = '1'\n",
    "# df12['Class'] = '2'\n",
    "# df13['Class'] = '3'\n",
    "# df14['Class'] = '4'\n",
    "# df15['Class'] = '5'\n",
    "# df16['Class'] = '6'\n",
    "# df17['Class'] = '7'\n",
    "# df18['Class'] = '8'\n",
    "# df19['Class'] = '9'\n",
    "# df20['Class'] = '10'\n",
    "\n",
    "'''Concatenate given Dataframes into a single unified Dataframe'''\n",
    "# frames1 = [df1, df2, df3, df4, df5, df6, df7, df8, df9, df10]\n",
    "# dataset2 = pd.concat(frames1)\n",
    "\n",
    "# frames2 = [df11, df12, df13, df14, df15, df16, df17, df18, df19, df20]\n",
    "# dataset2 = pd.concat(frames2)\n",
    "\n",
    "'''Drop Source information column'''\n",
    "# del dataset['Source.Name']  (Only to be done once)\n",
    "\n",
    "# dataset1.to_excel('final_train_dataset.xlsx')\n",
    "\n",
    "# dataset2.to_excel('final_test_dataset.xlsx')\n",
    "\n",
    "'''Data Loading done'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv('./data/train_dataset/final_train_dataset.csv')\n",
    "# test_data = pd.read_csv('./data/test_dataset/final_test_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 rows of train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.columns = train_data.columns.str.lower()\n",
    "# test_data.columns = test_data.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def cleanText(text):\n",
    "    \n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"can not\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"'ve\", \" have\", text)\n",
    "    text = re.sub(r\"'ll\", \" will\", text)\n",
    "    text = re.sub(r\"'re\", \" are\", text)\n",
    "\n",
    "    text = re.sub(r\"[0-9]+\", ' ', text)\n",
    "    text = re.sub(r\"-\", ' ', text)\n",
    "    \n",
    "    \n",
    "    text = text.strip().lower()\n",
    "    \n",
    "\n",
    "    default_stop_words = set(stopwords.words('english'))\n",
    "    default_stop_words.difference_update({'no', 'not', 'nor', 'too', 'any'})\n",
    "    stop_words = default_stop_words.union({\"'m\", \"n't\", \"'d\", \"'re\", \"'s\",\n",
    "                                           'would','must',\"'ve\",\"'ll\",'may'})\n",
    "\n",
    "    word_list = word_tokenize(text)\n",
    "    filtered_list = [w for w in word_list if not w in stop_words]\n",
    "    text = ' '.join(filtered_list)\n",
    "    \n",
    "    text = re.sub(r\"'\", ' ', text)\n",
    "    \n",
    "   \n",
    "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((i, \" \") for i in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "    \n",
    "\n",
    "    text = ' '.join([w for w in text.split() if len(w)>1])\n",
    "\n",
    "    # Replace multiple space with one space\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    \n",
    "    text = ''.join(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def NormalizeWithPOS(text):\n",
    "    # Lemmatization & Stemming according to POS tagging\n",
    "\n",
    "    word_list = word_tokenize(text)\n",
    "    rev = []\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    stemmer = PorterStemmer() \n",
    "    for word, tag in pos_tag(word_list):\n",
    "        if tag.startswith('J'):\n",
    "            w = lemmatizer.lemmatize(word, pos='a')\n",
    "        elif tag.startswith('V'):\n",
    "            w = lemmatizer.lemmatize(word, pos='v')\n",
    "        elif tag.startswith('N'):\n",
    "            w = lemmatizer.lemmatize(word, pos='n')\n",
    "        elif tag.startswith('R'):\n",
    "            w = lemmatizer.lemmatize(word, pos='r')\n",
    "        else:\n",
    "            w = word\n",
    "        w = stemmer.stem(w)\n",
    "        rev.append(w)\n",
    "    review = ' '.join(rev)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# train_data['clean_reviews'] = train_data['reviews'].apply(cleanText)\n",
    "# test_data['clean_reviews'] = test_data['reviews'].apply(cleanText)\n",
    "# train_data['clean_reviews_normalized'] = train_data['clean_reviews'].apply(NormalizeWithPOS)\n",
    "# test_data['clean_reviews_normalized'] = test_data['clean_reviews'].apply(NormalizeWithPOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the pre processed data into pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/pickle_data/train_data_preLowFreq.pkl', 'wb') as pickle_file:\n",
    "#     pickle.dump(train_data, pickle_file)\n",
    "# with open('./data/pickle_data/test_data_preLowFreq.pkl', 'wb') as pickle_file:\n",
    "#     pickle.dump(test_data, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data from pickled data for Low freqency word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/pickle_data/train_data_preLowFreq.pkl', 'rb') as pickle_file:\n",
    "#     train_data = pickle.load(pickle_file)\n",
    "# with open('./data/pickle_data/test_data_preLowFreq.pkl', 'rb') as pickle_file:\n",
    "#     test_data = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Frequency Words of Train Data for BOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_train1 = pd.Series(' '.join(train_data['clean_reviews_normalized']).split()).value_counts()\n",
    "# less_five_freq_train1 = freq_train1[(freq_train1 <5)]\n",
    "# print('Words occuring less than 5 are: ')\n",
    "# print('')\n",
    "# print(less_five_freq_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_train2 = pd.Series(' '.join(train_data['clean_reviews']).split()).value_counts()\n",
    "# less_five_freq_train2 = freq_train2[(freq_train2 <5)]\n",
    "# print('Words occuring less than 5 are: ')\n",
    "# print('')\n",
    "# print(less_five_freq_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Frequency Words of Test Data for BOWÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_test3 = pd.Series(' '.join(test_data['clean_reviews_normalized']).split()).value_counts()\n",
    "# less_five_freq_test3 = freq_test3[(freq_test3 <5)]\n",
    "# print('Words occuring less than 5 are: ')\n",
    "# print('')\n",
    "# print(less_five_freq_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_test4 = pd.Series(' '.join(test_data['clean_reviews']).split()).value_counts()\n",
    "# less_five_freq_test4 = freq_test4[(freq_test4 <5)]\n",
    "# print('Words occuring less than 5 are: ')\n",
    "# print('')\n",
    "# print(less_five_freq_test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove words with frequency less than 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# train_data['clean_reviews_normalized'] = train_data['clean_reviews_normalized'].apply(lambda x: ' '.join(x for x in x.split() if x not in less_five_freq_train1))\n",
    "# test_data['clean_reviews_normalized'] = test_data['clean_reviews_normalized'].apply(lambda x: ' '.join(x for x in x.split() if x not in less_five_freq_test3))\n",
    "\n",
    "\n",
    "# train_data['clean_reviews'] = train_data['clean_reviews'].apply(lambda x: ' '.join(x for x in x.split() if x not in less_five_freq_train2))\n",
    "# test_data['clean_reviews'] = test_data['clean_reviews'].apply(lambda x: ' '.join(x for x in x.split() if x not in less_five_freq_test4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the pre processed data post removal of words occuring less than 5 into pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/pickle_data/train_data_final.pkl', 'wb') as pickle_file:\n",
    "#     pickle.dump(train_data, pickle_file)\n",
    "# with open('./data/pickle_data/test_data_final.pkl', 'wb') as pickle_file:\n",
    "#     pickle.dump(test_data, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data from pickled data for Bag of Words Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/pickle_data/train_data_final.pkl', 'rb') as pickle_file:\n",
    "    train_data = pickle.load(pickle_file)\n",
    "with open('./data/pickle_data/test_data_final.pkl', 'rb') as pickle_file:\n",
    "    test_data = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A visual comparison of different cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A review example of dataset before cleaning:\n",
      "Sorry everyone,,, I know this is supposed to be an \"art\" film,, but wow, they should have handed out guns at the screening so people could blow their brains out and not watch. Although the scene design and photographic direction was excellent, this story is too painful to watch. The absence of a sound track was brutal. The loooonnnnng shots were too long. How long can you watch two people just sitting there and talking? Especially when the dialogue is two people complaining. I really had a hard time just getting through this film. The performances were excellent, but how much of that dark, sombre, uninspired, stuff can you take? The only thing i liked was Maureen Stapleton and her red dress and dancing scene. Otherwise this was a ripoff of Bergman. And i'm no fan f his either. I think anyone who says they enjoyed 1 1/2 hours of this is,, well, lying.\n",
      "\n",
      "clean_text:\n",
      "sorry everyone know supposed art film wow handed guns screening people could blow brains not watch although scene design photographic direction excellent story too painful watch absence sound track brutal shots too long long watch two people sitting talking especially dialogue two people complaining really hard time getting film performances excellent much dark sombre uninspired stuff take thing liked maureen stapleton red dress dancing scene otherwise ripoff bergman no fan either think anyone says enjoyed hours well lying\n",
      "\n",
      "clean_text_normalized:\n",
      "sorri everyon know suppos art film wow hand gun screen peopl could blow brain not watch although scene design photograph direct excel stori too pain watch absenc sound track brutal shot too long long watch two peopl sit talk especi dialogu two peopl complain realli hard time get film perform excel much dark sombr uninspir stuff take thing like maureen stapleton red dress danc scene otherwis ripoff bergman no fan either think anyon say enjoy hour well lie\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"A review example of dataset before cleaning:\")\n",
    "print(train_data.iloc[0]['reviews'], end='\\n\\n')\n",
    "\n",
    "print(\"clean_text:\")\n",
    "print(train_data.iloc[0]['clean_reviews'], end=\"\\n\\n\")\n",
    "\n",
    "print(\"clean_text_normalized:\")\n",
    "print(train_data.iloc[0]['clean_reviews_normalized'], end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer(stop_words='english')\n",
    "vectorizer2 = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "training_features_normalized = vectorizer1.fit_transform(train_data['clean_reviews_normalized'])\n",
    "testing_features_normalized = vectorizer1.transform(test_data['clean_reviews_normalized'])\n",
    "\n",
    "training_features = vectorizer2.fit_transform(train_data['clean_reviews'])\n",
    "testing_features = vectorizer2.transform(test_data['clean_reviews'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickling count vectorized data for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/pickle_data/training_features_normalized.pkl', 'wb') as pickle_file:\n",
    "#     pickle.dump(training_features_normalized, pickle_file)\n",
    "# with open('./data/pickle_data/testing_features_normalized.pkl', 'wb') as pickle_file:\n",
    "#     pickle.dump(testing_features_normalized, pickle_file)\n",
    "# with open('./data/pickle_data/training_features.pkl', 'wb') as pickle_file:\n",
    "#     pickle.dump(training_features, pickle_file)\n",
    "# with open('./data/pickle_data/testing_features.pkl', 'wb') as pickle_file:\n",
    "#     pickle.dump(testing_features, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/pickle_data/training_features_normalized.pkl', 'rb') as pickle_file:\n",
    "    training_features_normalized = pickle.load(pickle_file)\n",
    "with open('./data//pickle_data/testing_features_normalized.pkl', 'rb') as pickle_file:\n",
    "    testing_features_normalized = pickle.load(pickle_file)\n",
    "with open('./data/pickle_data/training_features.pkl', 'rb') as pickle_file:\n",
    "    training_features = pickle.load(pickle_file)\n",
    "with open('./data/pickle_data/testing_features.pkl', 'rb') as pickle_file:\n",
    "    testing_features = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 28397)\n"
     ]
    }
   ],
   "source": [
    "print(training_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 28397)\n"
     ]
    }
   ],
   "source": [
    "print(testing_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 19402)\n"
     ]
    }
   ],
   "source": [
    "print(training_features_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 19402)\n"
     ]
    }
   ],
   "source": [
    "print(testing_features_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResult(y_pred, y_prob):\n",
    "    acc = accuracy_score(test_data[\"class\"], y_pred)\n",
    "    # Result\n",
    "    print(\"Accuracy: {:.2f}\".format(acc*100),end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/pickle_data/train_data_final.pkl', 'rb') as pickle_file:\n",
    "    train_data = pickle.load(pickle_file)\n",
    "with open('./data/pickle_data/test_data_final.pkl', 'rb') as pickle_file:\n",
    "    test_data = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "model_normalized = RandomForestClassifier(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "model.fit(training_features, train_data[\"class\"])\n",
    "model_normalized.fit(training_features_normalized, train_data[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction for the whole of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_normalized = model_normalized.predict(testing_features_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(testing_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted values for whole of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 10,  1, ..., 10, 10, 10], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ..., 10, 10, 10], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy metric chosen is Mean Squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.19292"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_data['class'],predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.11096"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_data['class'],predict_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input and model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take in user input and convert it to a list followed that by converting it to a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a review: super movie\n"
     ]
    }
   ],
   "source": [
    "Input = input('Please enter a review: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Input = [Input]\n",
    "input_df = DataFrame(Input,columns=['reviews'])\n",
    "input_df['clean_reviews'] = input_df['reviews'].apply(cleanText)\n",
    "input_df['clean_reviews_normalized'] = input_df['clean_reviews'].apply(NormalizeWithPOS)\n",
    "input_testing_features = vectorizer2.transform(input_df['clean_reviews'])\n",
    "input_testing_features_normal = vectorizer1.transform(input_df['clean_reviews_normalized'])\n",
    "predict = model.predict(input_testing_features)\n",
    "predict_normal = model_normalized.predict(input_testing_features_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_normal[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
